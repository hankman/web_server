{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c6de6c-6bb7-40d0-8a89-090c913e7418",
   "metadata": {},
   "source": [
    "# 本站代码在MIT License下开源"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d59af-81db-48cd-8507-a41414ef6841",
   "metadata": {},
   "source": [
    "The MIT License (MIT)\n",
    "Copyright © 2022-present, Fan Chen\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36acfa-d0b8-49be-b774-cfed9c679dfd",
   "metadata": {},
   "source": [
    "# 说明\n",
    "该脚本每15分钟后台运行一次。如发现数据更新，则将更新数据处理后上传至redis数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967fa28c-2c50-4a96-8b0c-f95ab0b23de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from lxml import etree\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import datetime as dt\n",
    "import redis\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f831b-cd89-4b12-a450-7f5eb7c7d6be",
   "metadata": {},
   "source": [
    "## 抓取前准备，数据加载，预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b76cd5-7193-4c9e-bcf0-04465d536b3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 记录脚本运行时间并通知prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02405e68-27f1-4abf-8942-eda48a604473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_metrics(label, metrics, value):\n",
    "    requests.post(f'http://localhost:9091/metrics/job/data_grab/label/{label}', data=f'{metrics} {value}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86791c0-f6a5-4f24-a144-eca71d9fdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffe4b9-9b6c-4f8d-8f06-a7ea344e1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.strftime('%Y-%m-%d %H:%M:%S.%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef258d0f-2438-4d08-8362-6923cd015020",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_metrics('grab_time', 'run_start_time', int(n.timestamp()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41740fd-07c1-4ea2-8b9a-f3f0aa76df43",
   "metadata": {},
   "source": [
    "### 配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8886ee2-e39b-4fa3-91c9-6856dc547bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动配置“小区感染数据”页面链接\n",
    "CONFIG_FILE = 'data/manual.config'\n",
    "# 手动配置“感染人数”页面链接\n",
    "CNT_CONFIG_FILE = 'data/cnt_manual.config'\n",
    "# 原始数据文件保存和读取文件\n",
    "PICK_FILE = 'data/infect.pickle'\n",
    "CNT_FILE = 'data/cnt.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821ce6e-4a37-47f9-a384-4c56cc4bdb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 官方更正数据文件\n",
    "ADJUST_FOLDER = 'data/adjust/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaef78b-2b34-447f-8845-19cddcbc9862",
   "metadata": {},
   "source": [
    "### 加载往期数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f75bb1-78d8-491b-bced-1fab606625fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if_exist(path, cols):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc7663-5f5a-49a4-9a91-4baf95abbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = load_if_exist(PICK_FILE, ['Dist', 'Community', 'Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41373c81-60da-421d-b1ba-499fb2813bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_data = load_if_exist(CNT_FILE, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea980e-808e-40f4-9afe-cc0ce0ebe7d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 如果数据已经更新到前一天，就跳过网页抓取以避免被网站拉入黑名单\n",
    "- 本站曾经被卫健委官方网站拉入黑名单，于第二天解封。请各位抓取数据时谨慎对待。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd64193-c311-48c5-8986-fc92894247ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = dt.date.today() - dt.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0913ae-34fa-495e-b7ff-097293990211",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_data.empty and all_data.Date.max() >= yesterday:\n",
    "    processing_infect = False\n",
    "else:\n",
    "    processing_infect = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe26aa-3a89-4102-9674-985c6814c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cnt_data.empty and cnt_data.index.max() >= yesterday:\n",
    "    processing_cnt = False\n",
    "else:\n",
    "    processing_cnt = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673725b-745e-46f2-9cca-3791bb837bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_infect, processing_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70d3d8-d74d-4b3c-b072-736772c6a02e",
   "metadata": {},
   "source": [
    "## 网页抓取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521a886-2085-453d-88e3-80da97d5236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(url):\n",
    "    headers = {\n",
    "        'User-Agent': \n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fffe0-832a-44c7-9858-fdba72fad9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt\n",
    "infect_re = re.compile('.*(?P<month>\\d)月(?P<day>\\d*)日（0-24时）本市各区确诊病例、无症状感染者居住地信息')\n",
    "cnt_re = re.compile('.*((?P<year>\\d+)年)?(?P<month>\\d+)月(?P<day>\\d+)日.?(上海)?无?新增本土新冠肺炎确诊病例(?P<bl>\\d+)例.*本土无症状感染者(?P<wzz>\\d+)例.*')\n",
    "cnt_re2 = re.compile('(?P<month>\\d+)月(?P<day>\\d+)日.*上海(无)?新增(?P<bl>\\d+)例本土新冠.*新增(?P<wzz>\\d+)例本土无症状')\n",
    "\n",
    "def process_infect_title(node):\n",
    "    r = infect_re.match(node.getchildren()[0].attrib['title'])\n",
    "    return dt.date(2022, int(r['month']), int(r['day']))\n",
    "\n",
    "def parse_cnt_title_str(s):\n",
    "    r = cnt_re.match(s)\n",
    "    if r is None:\n",
    "        r = cnt_re2.match(s)\n",
    "    if r is None:\n",
    "        if '无新增本土新冠肺炎确诊病例' not in s:\n",
    "            print('cannot process cnt title \"{}\"'.format(s))\n",
    "        return None\n",
    "    return dt.date(2022, int(r['month']), int(r['day'])), int(r['bl']), int(r['wzz'])\n",
    "\n",
    "\n",
    "def process_cnt_title(node):\n",
    "    return parse_cnt_title_str(node.getchildren()[0].attrib['title'])\n",
    "\n",
    "\n",
    "def get_url(node):\n",
    "    return node.xpath('.//div/div/a[@class=\"url\"]')[0].attrib['href']\n",
    "\n",
    "\n",
    "def get_search_report_dict():\n",
    "    ret = get_page_search_infect_dict(\n",
    "        'https://ss.shanghai.gov.cn/search?q=本市各区确诊病例、无症状感染者居住地信息&page=2&view=&contentScope=2&dateOrder=1&tr=1&dr=&format=1&re=2&all=1&siteId=wsjkw.sh.gov.cn&siteArea=all',\n",
    "    )\n",
    "    ret.update(get_page_search_infect_dict(\n",
    "        'https://ss.shanghai.gov.cn/search?page=1&view=&contentScope=2&dateOrder=1&tr=1&dr=&format=1&re=2&all=1&debug=&siteId=wsjkw.sh.gov.cn&siteArea=all&q=本市各区确诊病例、无症状感染者居住地信息',\n",
    "    ))\n",
    "    ret.update(get_page_search_infect_dict(\n",
    "        'https://ss.shanghai.gov.cn/search?page=3&view=&contentScope=2&dateOrder=1&tr=1&dr=&format=1&re=2&all=1&debug=&siteId=wsjkw.sh.gov.cn&siteArea=all&q=本市各区确诊病例、无症状感染者居住地信息',\n",
    "    ))\n",
    "    ret.update(get_page_search_infect_dict(\n",
    "        'https://ss.shanghai.gov.cn/search?page=4&view=&contentScope=2&dateOrder=1&tr=1&dr=&format=1&re=2&all=1&debug=&siteId=wsjkw.sh.gov.cn&siteArea=all&q=本市各区确诊病例、无症状感染者居住地信息',\n",
    "    ))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_search_cnt_dict():\n",
    "    ret = get_page_search_cnt_dict(\n",
    "        'https://ss.shanghai.gov.cn/search?q=新增本土新冠肺炎&page=1&view=&contentScope=2&dateOrder=1&tr=1&dr=&format=1&re=2&all=1&siteId=wsjkw.sh.gov.cn&siteArea=all',\n",
    "    )\n",
    "    ret.update(get_page_search_cnt_dict(\n",
    "        'https://ss.shanghai.gov.cn/search?q=新增本土新冠肺炎&page=2&view=&contentScope=2&dateOrder=1&tr=1&dr=&format=1&re=2&all=1&siteId=wsjkw.sh.gov.cn&siteArea=all',\n",
    "    ))\n",
    "    ret.update(get_page_search_cnt_dict(\n",
    "        'https://ss.shanghai.gov.cn/search?q=新增本土新冠肺炎&page=3&view=&contentScope=2&dateOrder=1&tr=1&dr=&format=1&re=2&all=1&siteId=wsjkw.sh.gov.cn&siteArea=all',\n",
    "    ))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_page_search_nodes(url, key):\n",
    "    response = request(url)\n",
    "    html = etree.fromstring(response, etree.HTMLParser())\n",
    "    results = [i for i in html.xpath(\"//div[@id = 'results']\")[0].getchildren() if 'class' in i.attrib]\n",
    "    daily_result_nodes = [x for x in results if all([k in x.getchildren()[0].attrib['title'] for k in key])]\n",
    "    return daily_result_nodes\n",
    "\n",
    "def get_page_search_infect_dict(url):\n",
    "    daily_result_nodes = get_page_search_nodes(url, ['本市各区确诊病例、无症状感染者居住地信息'])\n",
    "    return {process_infect_title(i): get_url(i) for i in daily_result_nodes}\n",
    "\n",
    "\n",
    "def get_page_search_cnt_dict(url):\n",
    "    daily_result_nodes = get_page_search_nodes(url, ['新增', '本土新冠肺炎'])\n",
    "    cnt_ret = {}\n",
    "    for cnt_node in daily_result_nodes:\n",
    "        p_title = process_cnt_title(cnt_node)\n",
    "        if p_title is None:\n",
    "            continue\n",
    "        date, bl_cnt, wzz_cnt = p_title\n",
    "        cnt_ret[date] = get_url(cnt_node)\n",
    "    return cnt_ret\n",
    "\n",
    "\n",
    "def is_infect_item(node, key):\n",
    "    return all([k in node.xpath('./a')[0].text for k in key])\n",
    "\n",
    "def get_index_url(node):\n",
    "    ref_url = node.xpath('./a')[0].attrib['href'].strip()\n",
    "    if ref_url.startswith('https:'):\n",
    "        return ref_url\n",
    "    return 'https://wsjkw.sh.gov.cn' + ref_url\n",
    "\n",
    "def get_manual_config(file):\n",
    "    ret = {}\n",
    "    if not os.path.exists(file):\n",
    "        return ret\n",
    "\n",
    "    with open(CONFIG_FILE, 'r') as f:\n",
    "        for l in f:\n",
    "            l = l.strip()\n",
    "            date = dt.datetime.strptime(l[:l.index(' ')], '%Y-%m-%d').date()\n",
    "            url = l[l.index(' ') + 1:]\n",
    "            ret[date] = url\n",
    "    return ret\n",
    "\n",
    "def get_index_report():\n",
    "    response = request('https://wsjkw.sh.gov.cn/xwfb/index.html')\n",
    "    html = etree.fromstring(response, etree.HTMLParser())\n",
    "    pub_lists = html.xpath(\"//div[@id = 'main']\")[0].xpath('./div/div/ul')[0]\n",
    "    infect_list = [node for node in pub_lists if is_infect_item(node, '本市各区确诊病例、无症状感染者居住地信息')]\n",
    "    infect_ret = {process_infect_title(i): get_index_url(i) for i in infect_list}\n",
    "    \n",
    "    cnt_list = [node for node in pub_lists if is_infect_item(node, ['新增', '本土新冠肺炎'])]\n",
    "    cnt_ret = {}\n",
    "    for cnt_node in cnt_list:\n",
    "        date, bl_cnt, wzz_cnt = process_cnt_title(cnt_node)\n",
    "        cnt_ret[date] = get_index_url(cnt_node)\n",
    "    return infect_ret, cnt_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d8fd0-5c07-4b18-ad24-0a48bc2491bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "DIST_LIST = ['浦东新区', '黄浦区', '静安区', '徐汇区', '长宁区', '普陀区', '虹口区', '杨浦区', '宝山区',\n",
    "        '闵行区', '嘉定区', '金山区', '松江区', '青浦区', '奉贤区', '崇明区']\n",
    "\n",
    "\n",
    "def get_adjust_data(d):\n",
    "    adjust_file = os.path.join(ADJUST_FOLDER, f'{d.strftime(\"%Y-%m-%d\")}.diff')\n",
    "    if os.path.exists(adjust_file):\n",
    "        with open(adjust_file, 'r') as f:\n",
    "            return [i.strip() for i in f.read().split('\\n') if len(i.strip()) != 0]\n",
    "    return []\n",
    "    \n",
    "\n",
    "def convert_html_to_string(text):\n",
    "    class HTMLFilter(HTMLParser):\n",
    "        text = \"\"\n",
    "        def handle_data(self, data):\n",
    "            self.text += data\n",
    "        def handle_starttag(self, tag, attrs):\n",
    "            if tag == 'br':\n",
    "                self.text += '\\n'\n",
    "            elif tag == 'p':\n",
    "                self.text += ','\n",
    "            \n",
    "    f = HTMLFilter()\n",
    "    f.feed(text)\n",
    "    return f.text\n",
    "\n",
    "\n",
    "def filter_string(text):\n",
    "    if '各区信息如下' not in text:\n",
    "        print(text)\n",
    "    t = text[text.rfind('各区信息如下'):]\n",
    "    if 'jQuery(' in t:\n",
    "        t = t[:t.index('jQuery(')].strip()\n",
    "    else:\n",
    "        t = t[:t.index('var first_sceen__time')].strip()\n",
    "    return t.replace('\\xa0', '\\n')\n",
    "\n",
    "\n",
    "def parse_text(text, string_fileter):    \n",
    "    infect = {}\n",
    "    current = None\n",
    "\n",
    "    for line in re.split('[，,\\n]', string_fileter(text)):\n",
    "        line = line.strip(' ,')\n",
    "        if not line:\n",
    "            continue\n",
    "        if line in DIST_LIST:\n",
    "            # if line in infect:\n",
    "            #     print(line)\n",
    "            # assert(line not in infect)\n",
    "            current = line\n",
    "            continue\n",
    "        if current is None:\n",
    "            continue\n",
    "        if (line[:1].isdigit() or \n",
    "            '居住于' in line or \n",
    "            '终末消毒措施' in line or \n",
    "            '上海发布' in line or \n",
    "            '资料' in line or \n",
    "            '病例' in line or \n",
    "            '新增' in line or \n",
    "            '措施' in line or \n",
    "            '2022年' in line or\n",
    "            '滑动' in line or\n",
    "            ('月' in line and '日' in line) or\n",
    "            '感染' in line or\n",
    "            '编辑' in line or\n",
    "            '目前' in line or\n",
    "            '滑动查看更多' in line\n",
    "           ):\n",
    "            continue\n",
    "        inf_list = [i.replace(' ', '') for i in re.split('[,.，。、]', line) if i]\n",
    "        if current in infect:\n",
    "            infect[current] += inf_list\n",
    "        else:\n",
    "            infect[current] = inf_list\n",
    "    return infect\n",
    "\n",
    "\n",
    "def parse_page_content(page_content, adjust_data, string_filter=filter_string):\n",
    "    data = parse_text(convert_html_to_string(page_content), string_filter)\n",
    "    for i in adjust_data:\n",
    "        _dist, _addr = i[1:].split(',')\n",
    "        if i.startswith('+'):\n",
    "            data[_dist].append(_addr)\n",
    "        elif i.startswith('-') and _addr in data[_dist]:\n",
    "            data[_dist].remove(_addr)\n",
    "        else:\n",
    "            print('Wrong adjust data {i}')\n",
    "    for dist in data:\n",
    "        data[dist] = list(set(data[dist]))\n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_infect_page(url, adjust_data):\n",
    "    t = request(url)\n",
    "    return parse_page_content(t, adjust_data)\n",
    "\n",
    "\n",
    "def create_inf_df(inf_data):\n",
    "    dist, com = [], []\n",
    "    for _dist, _coms in inf_data.items():\n",
    "        for _com in _coms:\n",
    "            dist.append(_dist)\n",
    "            com.append(_com)\n",
    "    return pd.DataFrame({'Dist': dist, 'Community': com})\n",
    "\n",
    "\n",
    "def trans_data(all_data):\n",
    "    d, dist, com = [], [], []\n",
    "    for _d, _inf in all_data.items():\n",
    "        for _dist, _coms in _inf.items():\n",
    "            for _com in _coms:\n",
    "                d.append(_d)\n",
    "                dist.append(_dist)\n",
    "                com.append(_com)\n",
    "    return pd.DataFrame({'Date': d, 'Dist': dist, 'Community': com})\n",
    "\n",
    "\n",
    "def vague_search_print(comm, data):\n",
    "    if comm != '*':\n",
    "        df = data[data.Community.str.contains(comm)].set_index(\n",
    "            ['Dist', 'Community', 'Date']).sort_index(\n",
    "                ascending=[True, True, True, False])\n",
    "    else:\n",
    "        df = data.set_index(\n",
    "            ['Dist', 'Community', 'Date']).sort_index(\n",
    "                ascending=[True, True, True, False])\n",
    "    df.index.names = ['区', '地址', '报告日期']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cd7b7-0953-40da-acf4-035f4a050480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def filter_cnt_string(s):\n",
    "    # s = s[:s.index('籍')]\n",
    "    sec = re.split('[ ,、，。\\n\\xa0]', s)\n",
    "    for n, l in enumerate(sec):\n",
    "        if '病例1—' in l:\n",
    "            return [l for l in sec[n:] if len(l) != 0]\n",
    "    return [i for i in sec[sec.index('病例1'):] if len(i) != 0]\n",
    "\n",
    "\n",
    "def get_cnt_index(l, kind):\n",
    "    l = l.strip()\n",
    "    if l.isdigit():\n",
    "        return int(l)\n",
    "    return int(l[l.index(kind)+len(kind):])\n",
    "\n",
    "\n",
    "def check_single_item(l, kind):\n",
    "    l = l.strip()\n",
    "    return l.startswith(kind) and l[len(kind):].isdigit()\n",
    "\n",
    "\n",
    "def check_item_start(l, kind):\n",
    "    if '—' in l:\n",
    "        s, e = l.split('—', 1)\n",
    "        s_flag = check_single_item(s, kind)\n",
    "        e_flag = check_single_item(e, kind)\n",
    "        if not s_flag:\n",
    "            return False\n",
    "        if e_flag:\n",
    "            return True\n",
    "        else:\n",
    "            return e.isdigit()\n",
    "    else:\n",
    "        return check_single_item(l, kind)\n",
    "\n",
    "\n",
    "def parse_cnt_page(sec):\n",
    "    curr_cnt = 0\n",
    "    curr_index = 0\n",
    "    bl_ret = defaultdict(int)\n",
    "    wzz_ret = defaultdict(int)\n",
    "\n",
    "    curr_kind = None\n",
    "    curr_ret = None\n",
    "    bl, wzz = '病例', '无症状感染者'\n",
    "    prev = ''\n",
    "    \n",
    "    for n, l in enumerate(sec):\n",
    "        processed = False\n",
    "        for i in [l, prev+l] if prev else [l]:\n",
    "            kind = None\n",
    "            if check_item_start(i, bl):\n",
    "                assert curr_kind is None\n",
    "                kind = bl\n",
    "                curr_ret = bl_ret\n",
    "            elif check_item_start(i, wzz):\n",
    "                assert curr_kind is None\n",
    "                kind = wzz\n",
    "                curr_ret = wzz_ret\n",
    "            elif i.startswith('居住于'):\n",
    "                if curr_cnt == 0:\n",
    "                    print(f'missing on {n}:{i}')\n",
    "                    prev = ''\n",
    "                    continue\n",
    "                # assert curr_cnt != 0\n",
    "                dist = i[i.index('居住于') + 3:].strip()\n",
    "                if len(dist) == 0 or dist not in DIST_LIST:\n",
    "                    break\n",
    "                curr_ret[dist] += curr_cnt\n",
    "                curr_cnt = 0\n",
    "                curr_ret = None\n",
    "                processed = True\n",
    "                break\n",
    "\n",
    "            if kind is not None:\n",
    "                if '—' in i:\n",
    "                    assert curr_cnt == 0\n",
    "                    b, e = i.split('—')\n",
    "                    ind_b, ind_e = get_cnt_index(b, kind), get_cnt_index(e, kind)\n",
    "                    curr_cnt = ind_e - ind_b + 1\n",
    "                else:\n",
    "                    curr_cnt += 1\n",
    "                processed = True\n",
    "                break\n",
    "        prev = '' if processed else i\n",
    "            \n",
    "    return bl_ret, wzz_ret\n",
    "\n",
    "\n",
    "def create_cnt_df(bl_ret, wzz_ret, date):\n",
    "    bl_ret['Kind'] = 'BL'\n",
    "    wzz_ret['Kind'] = 'WZZ'\n",
    "    return pd.concat([pd.DataFrame(bl_ret, index=[date]), pd.DataFrame(wzz_ret, index=[date])])\n",
    "\n",
    "\n",
    "def grab_infect_count(url):\n",
    "    text = request(url)\n",
    "    title_str = text[text.index('<title>')+len('<title>'):text.index('</title>')]\n",
    "    d, bl, wzz = parse_cnt_title_str(title_str)\n",
    "    s = convert_html_to_string(text)\n",
    "    sec = filter_cnt_string(s)\n",
    "    bl_ret, wzz_ret = parse_cnt_page(sec)\n",
    "    df = create_cnt_df(bl_ret, wzz_ret, d)\n",
    "    _bl, _wzz = df.set_index('Kind').T.sum()\n",
    "    if _bl != bl or _wzz != wzz:\n",
    "        raise Exception(f'Parsed unmatched count for {d.strftime(\"%Y-%m-%d\")}:{url}')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cab743-4729-4587-8473-e613a864e1a6",
   "metadata": {},
   "source": [
    "### 抓取包含疫情数据的页面链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e41bf0-b71e-40b0-b592-0790d801b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 从卫健委网站新闻发布索引页抓取数据页面链接\n",
    "if processing_infect or processing_cnt:\n",
    "    try:\n",
    "        indexed_infect, indexed_cnt = get_index_report()\n",
    "    except Exception as e:\n",
    "        print(f'processing index page failed with {e}')\n",
    "        publish_metrics('Infect', 'update_status', 0)\n",
    "        publish_metrics('Count', 'update_status', 0)\n",
    "        \n",
    "\n",
    "# 从卫健委网站搜索页抓取感染小区数据页面链接\n",
    "if processing_infect:\n",
    "    try:\n",
    "        infect_dict = get_manual_config(CONFIG_FILE)\n",
    "        infect_dict.update(get_search_report_dict())\n",
    "        infect_dict.update(indexed_infect)\n",
    "        print('processing infect:')\n",
    "        display(infect_dict)\n",
    "    except Exception as e:\n",
    "        print(f'processing infect dict failed with {e}')\n",
    "        publish_metrics('Infect', 'update_status', 0)\n",
    "        \n",
    "\n",
    "# 从卫健委网站搜索页抓取感染人数数据页面链接\n",
    "if processing_cnt:\n",
    "    try:\n",
    "        cnt_dict = get_manual_config(CNT_CONFIG_FILE)\n",
    "        cnt_dict.update(get_search_cnt_dict())\n",
    "        cnt_dict.update(indexed_cnt)\n",
    "        print('processing cnt:')\n",
    "        display(cnt_dict)\n",
    "    except Exception as e:\n",
    "        print(f'processing count dict failed with {e}')\n",
    "        publish_metrics('Count', 'update_status', 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c9193-c0c6-4965-a053-d152dc8d94fe",
   "metadata": {},
   "source": [
    "### 抓取疫情数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48bec2-4da4-49d2-88f3-33d5e2546cb3",
   "metadata": {},
   "source": [
    "#### 抓取小区感染数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eaeb7d-ef34-4422-a6cb-71546a941a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 抓取感染小区页面数据，仅抓取更新数据\n",
    "inf_data_changed = False\n",
    "if processing_infect:\n",
    "    dates = all_data.Date.unique()\n",
    "    inf_data = [all_data]\n",
    "    for d, url in infect_dict.items():\n",
    "        if d in dates:\n",
    "            continue\n",
    "        print('processing infect data for {}'.format(d.strftime('%Y-%m-%d')))\n",
    "        try:\n",
    "            adjust_data = get_adjust_data(d)\n",
    "            df = create_inf_df(parse_infect_page(url, adjust_data))\n",
    "            df['Date'] = d\n",
    "            inf_data.append(df)\n",
    "            inf_data_changed = True\n",
    "        except Exception as e:\n",
    "            print(f'processing data error for {d.strftime(\"%Y-%m-%d\")} as {e}')\n",
    "            publish_metrics('Infect', 'update_status', 0)\n",
    "    all_data = pd.concat(inf_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1a76a-c223-4a17-8b32-e031a23de538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afd234-9039-45ca-8d2c-f347ad2ac201",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = all_data.Date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345fc62-7000-4342-817e-2e7aba1c67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f83c9-a668-4013-822b-01170d94718c",
   "metadata": {},
   "source": [
    "#### 抓取微博数据\n",
    "后期官方会先在“上海发布”微信公众号和“上海发布”微博发布最新小区感染数据。过数小时以后，微信公众号的文章链接会出现在官方网站上。为第一时间更新数据，本站选择的抓取微博的数据。<br>\n",
    "一般来说，微信公众号的发布时间会比微博早半个小时左右。但由于微信把官方公开信息也当他家宝贝，捂得非常紧（当然，花钱是可以买的），我没有时间和精力去破解，最后我还是选择从微博上抓取数据。<br>\n",
    "微博本身也有防抓取的措施，本人相信如果微博也想像微信一样紧紧捂住数据是完全有能力办到的。但微博还是颇有“良心”地留下了少量抓取的口子。所以在这里，我就不公开抓取的代码了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc8af2-09ec-494f-b232-583b4cc0b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run grab_weibo_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dcdf21-9e36-401a-9c31-20fef54f69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIBO_METRICS = 'weibo_import_status'\n",
    "\n",
    "if processing_infect:\n",
    "    try:\n",
    "        weibo_data = grab_from_weibo(max_date)\n",
    "        if not weibo_data.empty:\n",
    "            print('import weibo data on {}'.format(weibo_data.Date.unique()))\n",
    "            all_data = pd.concat([all_data, weibo_data], ignore_index=True)\n",
    "            inf_data_changed = True\n",
    "            max_date = all_data.Date.max()\n",
    "            print(f'max_date updated to {max_date}')\n",
    "            publish_metrics('Infect', WEIBO_METRICS, 2)\n",
    "        else:\n",
    "            publish_metrics('Infect', WEIBO_METRICS, 1)\n",
    "    except Exception as e:\n",
    "        print(f'failed to capture data from weibo, not end of the world. {e}')\n",
    "        publish_metrics('Infect', WEIBO_METRICS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925ebb4-1d04-4cae-9bd5-3a689b03c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 官方数据偶尔会将行政区加到地址前面，为统一数据格式，这里同一去除行政区\n",
    "for d in DIST_LIST:\n",
    "    all_data.loc[all_data.Community.str.startswith(d), 'Community'] = all_data.Community.str.slice(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14820d5-4cf0-4c83-9bf1-ec3a0c11785a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7375e517-93a0-46c1-9175-b0dcd0a35a66",
   "metadata": {},
   "source": [
    "#### 抓取感染人数数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b0091-a323-47e7-ae51-60c0bbd8680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnt_data_changed = False\n",
    "need_restart = inf_data_changed\n",
    "if processing_cnt:\n",
    "    cnt_dates = cnt_data.index\n",
    "    cnt_data_list = [cnt_data]\n",
    "    for d, url in cnt_dict.items():\n",
    "        if d in cnt_dates or d < dt.date(2022, 3, 18):\n",
    "            continue\n",
    "        print('processing cnt data for {}'.format(d.strftime('%Y-%m-%d')))\n",
    "        try:\n",
    "            df = grab_infect_count(url)\n",
    "            if d != df.index.unique()[0]:\n",
    "                raise Exception(f'processing data error for {d.strftime(\"%Y-%m-%d\")}')\n",
    "            cnt_data_list.append(df)\n",
    "            cnt_data_changed = True\n",
    "            if max_date >= d:\n",
    "                need_restart = True\n",
    "        except Exception as e:\n",
    "            print(f'processing data error for {d.strftime(\"%Y-%m-%d\")} as {e}')\n",
    "            publish_metrics('Count', 'update_status', 0)\n",
    "    cnt_data = pd.concat(cnt_data_list)\n",
    "    cnt_data.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018e350-41c7-4c2d-ac6b-747e26c6e934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c95a540-7afe-40c9-8861-36c86090cfe0",
   "metadata": {},
   "source": [
    "## 数据保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e661fd9-ad98-4541-b680-af9c0fcd0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "if inf_data_changed:\n",
    "    print(f'updating infect file at {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}')\n",
    "    with open(PICK_FILE, 'wb') as f:\n",
    "        pickle.dump(all_data, f)\n",
    "    os.system(f'chmod a+r {PICK_FILE}')\n",
    "    publish_metrics('Infect', 'update_status', 2)\n",
    "elif processing_infect:\n",
    "    publish_metrics('Infect', 'update_status', 1)\n",
    "    \n",
    "\n",
    "if cnt_data_changed:\n",
    "    print(f'updating cnt file at {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}')\n",
    "    with open(CNT_FILE, 'wb') as f:\n",
    "        pickle.dump(cnt_data, f)\n",
    "    os.system(f'chmod a+r {CNT_FILE}')\n",
    "    publish_metrics('Count', 'update_status', 2)\n",
    "elif processing_cnt:\n",
    "    publish_metrics('Count', 'update_status', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f23083-e1e2-448e-9592-b8f683774232",
   "metadata": {},
   "outputs": [],
   "source": [
    "need_restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86a552-fb80-41dd-817d-40bf97cd9d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6bb9785-6354-4161-a7af-4b8e7c4e7b67",
   "metadata": {},
   "source": [
    "## 更新Redis数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69403a-a432-4750-b0a4-161fb7febde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_redis(df):\n",
    "    key = df.Community.unique()[0]\n",
    "    df['Date'] = pd.to_datetime(df.Date).dt.strftime('%Y/%-m/%-d')\n",
    "    REDIS.set(key, df.to_csv(index=False, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b851362-cf97-480f-891c-57330362437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if need_restart:\n",
    "    REDIS = redis.Redis(host='localhost', port=6379, db=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee114c88-d29a-4076-96fc-b6218dd8e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if inf_data_changed:\n",
    "    print('refresh redis infect data')\n",
    "    all_data.groupby('Community').apply(insert_to_redis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca693d7-ac91-4e0d-92aa-ee625dcb0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if need_restart:\n",
    "    dist_summary = all_data[\n",
    "        all_data.Date.isin(sorted(all_data.Date.unique())[-5:])\n",
    "    ].groupby(['Dist', 'Date']).size().rename('Counts'\n",
    "    ).sort_index().reset_index().set_index(['Dist', 'Date']).unstack().fillna(0).astype(int)\n",
    "    dist_summary = pd.concat([dist_summary, dist_summary.sum().rename('全市').to_frame().T])\n",
    "\n",
    "    dist_summary.columns = [d[1].strftime('%-m月%-d日') for d in dist_summary.columns]\n",
    "    dist_summary.index.name = None\n",
    "    dist_summary = dist_summary.sort_index().style.background_gradient(\n",
    "        axis=None, cmap='Oranges', high=0.85, text_color_threshold=0, subset=(\n",
    "            [i for i in dist_summary.index if i != '全市'], dist_summary.columns))\n",
    "    dist_summary = dist_summary.background_gradient(\n",
    "        axis=None, cmap='Blues', high=0.85, low=0.25, text_color_threshold=0,\n",
    "        subset=(['全市'], dist_summary.columns))\n",
    "    REDIS.set('dist_summary', dist_summary.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bff84-ae0b-496d-8268-8bc41e5afd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if need_restart:\n",
    "    df = cnt_data.loc[cnt_data.index.unique().sort_values(\n",
    "        ascending=False)[:5]].fillna(0)\n",
    "    df['全市'] = df.sum(axis=1)\n",
    "    df = df.reset_index().set_index(['Date', 'Kind']).unstack(\n",
    "        ).T.fillna(0).astype(int)\n",
    "\n",
    "    df.columns = [d.strftime('%-m月%-d日') for d in df.columns]\n",
    "    df.index.names = (None, None)\n",
    "    df_log = df.applymap(lambda x: log(x) if x != 0 else 0)\n",
    "    styled_df = df.sort_index().style.background_gradient(\n",
    "        axis=None, cmap='Oranges', text_color_threshold=0,\n",
    "        subset=([i for i in df.index if i[1] == 'BL' and i[0] != '全市'], df.columns),\n",
    "        gmap=df_log, high=0.85).background_gradient(\n",
    "            axis=None, cmap='Blues', text_color_threshold=0,\n",
    "            subset=([i for i in df.index if i[1] == 'WZZ' and i[0] != '全市'], df.columns),\n",
    "            gmap=df_log, high=0.85).background_gradient(\n",
    "                axis=None, cmap='Purples', text_color_threshold=0,\n",
    "                subset=([i for i in df.index if i[1] == 'BL' and i[0] == '全市'], df.columns),\n",
    "                high=0.85, low=0.25).background_gradient(\n",
    "                    axis=None, cmap='Greens', text_color_threshold=0,\n",
    "                    subset=([i for i in df.index if i[1] == 'WZZ' and i[0] == '全市'], df.columns),\n",
    "                    high=0.85, low=0.25).format_index(\n",
    "                        formatter=lambda x: '确诊' if x == 'BL' else '无症状', level=1)\n",
    "    REDIS.set('cnt_summary', styled_df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098baf9-69d4-42c4-9867-930cd9704a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if need_restart:\n",
    "    REDIS.set('updated_date', max_date.strftime('%Y年%-m月%-d日'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cf700-cefd-4784-8706-4d4b8ef044e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee03adf6-9266-4274-b59f-552f513b96c1",
   "metadata": {},
   "source": [
    "## 重启服务\n",
    "为加快服务器应答速度，减少服务器端压力，本站尽量将低频更新页面提前计算好并常驻内存。所以，数据更新后，低频更新页面要重新计算加载，需要重启服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aed85e-dd14-400c-a963-51323315c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if need_restart:\n",
    "    print(f'restarting gunicorn instance at {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}')\n",
    "    os.system('systemctl restart gunicorn')\n",
    "    print(f'shutdown nginx at {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}')\n",
    "    os.system('systemctl stop nginx')\n",
    "    print(f'clear nginx cache at {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}')\n",
    "    os.system('rm -rf /var/lib/nginx/cache/*')\n",
    "    print(f'start nginx at {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}')\n",
    "    os.system('systemctl start nginx')\n",
    "    print(f'system restarted at {dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6694331-05ec-4a19-a01c-e352cba366a9",
   "metadata": {},
   "source": [
    "## 发送服务状态邮件通知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660001b0-ac67-4241-bd4c-e5bc94b98dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notify.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175e3f4-1f5a-4e53-894e-922c3cae8a0f",
   "metadata": {},
   "source": [
    "## 发送prometheus监控数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3e2ed-e34b-4474-90e3-afca57762eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_metrics('Infect', 'updated_date', int(dt.datetime.combine(max_date, dt.time()).timestamp()))\n",
    "publish_metrics('Count', 'updated_date', int(dt.datetime.combine(cnt_data.index.max(), dt.time()).timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915063c-9896-49fb-b147-3cee33391a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebceb800-11dc-4e6c-9a4c-ee3b015739f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
